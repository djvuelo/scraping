## Geekbrains: методы сбора и обработки данных из сети Интернет
### Как использовать (Mac OS terminal):

```shell
python3 -m venv myvenv
```
```shell
. myvenv/bin/activate
```
```shell
pip install -r requirements.txt 
```
### Уроки:
1. #### Основы клиент-серверного взаимодействия. Парсинг API
    - ##### Задания:
        - Посмотреть документацию к API GitHub, разобраться как вывести список репозиториев для конкретного пользователя, сохранить JSON-вывод в файле *.json.
        - Изучить список открытых API (https://www.programmableweb.com/category/all/apis). Найти среди них любое, требующее авторизацию (любого типа). Выполнить запросы к нему, пройдя авторизацию. Ответ сервера записать в файл.
        Если нет желания заморачиваться с поиском, возьмите API вконтакте (https://vk.com/dev/first_guide). Сделайте запрос, чтобы получить список всех сообществ на которые вы подписаны.

2. #### Парсинг HTML. BeautifulSoup, MongoDB
    - ##### Задания:
        - Необходимо собрать информацию о вакансиях на вводимую должность (используем input или через аргументы получаем должность) с сайтов HH(обязательно) и/или Superjob(по желанию). Приложение должно анализировать несколько страниц сайта (также вводим через input или аргументы). Получившийся список должен содержать в себе минимум:
            - Наименование вакансии.
            - Предлагаемую зарплату (разносим в три поля: минимальная и максимальная и валюта. цифры преобразуем к цифрам).
            - Ссылку на саму вакансию.
            - Сайт, откуда собрана вакансия.
        - По желанию можно добавить ещё параметры вакансии (например, работодателя и расположение). Структура должна быть одинаковая для вакансий с обоих сайтов. Общий результат можно вывести с помощью dataFrame через pandas. Сохраните в json либо csv.